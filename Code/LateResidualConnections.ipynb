{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20392edf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T01:25:28.090353Z",
     "start_time": "2021-11-02T01:25:28.087934Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from termcolor import colored\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f46d00",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc829cd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T01:25:28.821557Z",
     "start_time": "2021-11-02T01:25:28.818326Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.residual_connection = torch.nn.Identity()\n",
    "        \n",
    "    def forward (self, x):\n",
    "        return self.residual_connection(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b85c558",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T01:32:01.555919Z",
     "start_time": "2021-11-02T01:32:01.540021Z"
    }
   },
   "outputs": [],
   "source": [
    "class NNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_inputs, n_hiddens_list, n_outputs, method=None, verbose=False):\n",
    "        super().__init__()  # call parent class (torch.nn.Module) constructor\n",
    "        self.verbose = verbose\n",
    "      \n",
    "        \n",
    "        # Set self.n_hiddens_per_layer to [] if argument is 0, [], or [0]\n",
    "        if n_hiddens_list == 0 or n_hiddens_list == [] or n_hiddens_list == [0]:\n",
    "            layers = torch.nn.Linear(n_inputs, n_outputs)\n",
    "            \n",
    "        else:\n",
    "            self.input_layer = torch.nn.Linear(n_inputs, n_hiddens_list[0])\n",
    "            self.input_relu = torch.nn.ReLU()\n",
    "            \n",
    "            layers = []\n",
    "            self.residual_layers = []\n",
    "            self.regular_layers = []\n",
    "            \n",
    "            for nh in n_hiddens_list[:-1]:\n",
    "                self.regular_layers.append(torch.nn.Linear(n_inputs, nh))\n",
    "                layers.append(self.regular_layers[-1])\n",
    "                self.regular_layers.append(torch.nn.ReLU())\n",
    "                layers.append(self.regular_layers[-1])\n",
    "                n_inputs = nh\n",
    "                self.residual_layers.append(self.get_residual_layer())\n",
    "                layers.append(self.residual_layers[-1])\n",
    "                \n",
    "                \n",
    "            layers.append(torch.nn.Linear(n_inputs, n_hiddens_list[-1]))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            self.output_layer = torch.nn.Linear(np.sum(n_hiddens_list), n_outputs)\n",
    "            layers.append(self.output_layer)\n",
    "            \n",
    "            self.model = torch.nn.Sequential(*layers)\n",
    "            \n",
    "            \n",
    "        self.Xmeans = None\n",
    "        self.Xstds = None\n",
    "        self.Tmeans = None\n",
    "        self.Tstds = None\n",
    "\n",
    "        self.error_trace = []\n",
    "        self.method = method\n",
    "        \n",
    "    def get_residual_layer(self):\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock())\n",
    "        return torch.nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        residual_outs = []\n",
    "        self.layer_outputs = []\n",
    "        \n",
    "        for index, layer in enumerate(self.model):\n",
    "            if index != len(self.model)-1:\n",
    "                # For Regular Layers          \n",
    "                if isinstance(layer, torch.nn.Linear):\n",
    "                    x = layer(x)\n",
    "                elif isinstance(layer, torch.nn.ReLU):\n",
    "                    x = layer(x)\n",
    "                    self.layer_outputs.append(x.detach().numpy())\n",
    "\n",
    "                # For Residual Layers\n",
    "                elif isinstance(layer, torch.nn.Sequential):\n",
    "                    residual_outs.append(x)\n",
    "                else:\n",
    "                    raise Exception(f'{layer} is not an appropriate layer.')\n",
    "        \n",
    "        # Concat all residual outs and normal out\n",
    "        # push through to the outputlayer\n",
    "        residual_outs.append(x)\n",
    "        all_outs = torch.cat(tuple(residual_outs),dim=1)        \n",
    "        x = self.output_layer(all_outs)\n",
    "\n",
    "        return x\n",
    "        \n",
    "\n",
    "    def train(self, X, T, n_epochs, learning_rate, train_style, verbose=True):\n",
    "\n",
    "        # Set data matrices to torch.tensors if not already.\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.from_numpy(X).float()\n",
    "        if not isinstance(T, torch.Tensor):\n",
    "            T = torch.from_numpy(T).float()\n",
    "            \n",
    "        # Calculate standardization parameters if not already calculated\n",
    "        if self.Xmeans is None:\n",
    "            self.Xmeans = X.mean(0)\n",
    "            self.Xstds = X.std(0)\n",
    "            self.Xstds[self.Xstds == 0] = 1\n",
    "            self.Tmeans = T.mean(0)\n",
    "            self.Tstds = T.std(0)\n",
    "            self.Tstds[self.Tstds == 0] = 1\n",
    "\n",
    "            \n",
    "        # Standardize inputs and targets\n",
    "        X = (X - self.Xmeans) / self.Xstds\n",
    "        T = (T - self.Tmeans) / self.Tstds\n",
    "        \n",
    "        \n",
    "        # Set optimizer to Adam and loss functions to MSELoss\n",
    "        optimizer = None\n",
    "        if self.method == 'adam':\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        elif self.method == 'sgd':\n",
    "            optimizer = torch.optim.SGD(self.parameters(), lr=learning_rate)\n",
    "        else:\n",
    "            raise Exception(f'Must select Adam or SGD Optimizer. Got {self.method}')\n",
    "        mse_func = torch.nn.MSELoss()\n",
    "\n",
    "        unstndErr = lambda err:(torch.sqrt(err) * self.Tstds)[0]\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            # Compute Prediction and loss\n",
    "            if train_style == 'batch':\n",
    "                Y = self.forward(X)\n",
    "                mse = mse_func(T, Y)\n",
    "            else:\n",
    "                Y = self.forward(X[epoch % len(X)].reshape(-1,1))\n",
    "                mse = mse_func(T[epoch % len(T)].reshape(-1,1), Y)\n",
    "            \n",
    "            # Backpropigation\n",
    "            optimizer.zero_grad()\n",
    "            mse.backward()\n",
    "            optimizer.step()\n",
    "          \n",
    "            self.error_trace.append(unstndErr(mse))\n",
    "            \n",
    "            if verbose and ((epoch+1 == n_epochs) or np.mod(epoch+1 , (n_epochs // 10)) == 0):\n",
    "                print(f'Epoch {epoch + 1}: RMSE {self.error_trace[-1]:.3f}')\n",
    "            \n",
    "\n",
    "    def use(self, X):\n",
    " \n",
    "       # Set input matrix to torch.tensors if not already.\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.from_numpy(X).float()\n",
    "\n",
    "        # Standardize X\n",
    "\n",
    "        X = (X - self.Xmeans) / self.Xstds\n",
    "        \n",
    "        # Do forward pass and unstandardize resulting output. Assign to variable Y.\n",
    "        Y = self.forward(X)\n",
    "        Y = (Y * self.Tstds) + self.Tmeans\n",
    "        # Return output Y after detaching from computation graph and converting to numpy\n",
    "\n",
    "        return Y.detach().numpy()\n",
    "\n",
    "\n",
    "    def dead_neurons(self, verbose=True):\n",
    "        dead_neurons = 0\n",
    "        all_layer_dead = []\n",
    "        dead_layers = 0\n",
    "        \n",
    "        for layer in self.layer_outputs:\n",
    "            for neuron in layer.T:\n",
    "                if np.all(neuron == 0):\n",
    "                    dead_neurons += 1\n",
    "                    all_layer_dead.append(True)\n",
    "            if np.all(all_layer_dead):\n",
    "                dead_layers += 1\n",
    "            all_layer_dead = []\n",
    "        return dead_neurons, dead_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d043ce0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T01:32:01.829445Z",
     "start_time": "2021-11-02T01:32:01.827290Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmse(Y, T):\n",
    "    return np.sqrt(np.mean((T - Y)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221df9e2",
   "metadata": {},
   "source": [
    "## Absolute Value Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0b239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T01:32:02.269139Z",
     "start_time": "2021-11-02T01:32:02.256913Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Rnd.csv')\n",
    "X = df['X'].values\n",
    "X = X.reshape(-1,1)\n",
    "\n",
    "T = df['T'].values\n",
    "T = T.reshape(-1, 1)\n",
    "\n",
    "X.shape, T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5270a9",
   "metadata": {},
   "source": [
    "## Low Hanging Fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea61bdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T01:32:03.034729Z",
     "start_time": "2021-11-02T01:32:03.017199Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_hiddens = [4 for _ in range(5)]\n",
    "n = NNet(1, n_hiddens, 1, method='adam') \n",
    "\n",
    "# print(n.model)\n",
    "n.train(X, T, 1500, 0.01, train_style='batch')\n",
    "# print(n.layer_outputs)\n",
    "Y = n.use(X)\n",
    "print(f'FINAL RMSE: {rmse(Y, T):.2f}')\n",
    "print(n.dead_neurons())\n",
    "\n",
    "# top, bottom = n.dead_neurons(X)\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(n.error_trace, label='Adam')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.ylim((0.0, 0.3))\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(Y, '-s', label='Adam')\n",
    "plt.plot(T, '-o', label='Target')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Target or Predicted')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in n.model:\n",
    "    if isinstance(layer, torch.nn.Linear):\n",
    "        print(layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a53727",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T01:31:32.363122Z",
     "start_time": "2021-11-02T01:31:32.358752Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_graph(X, model, lr, n_hiddens, method, iteration, train_style, did_converge):\n",
    "\n",
    "    depth = f'{len(n_hiddens)}'\n",
    "    arch = f'[2 for _ in range({len(n_hiddens)})]'\n",
    "    \n",
    "    color = 'blue' if method =='Adam' else 'orange'\n",
    "\n",
    "    conv_or_no_conv = 'c' if did_converge else 'nc'\n",
    "\n",
    "    lr_dir = None\n",
    "    if lr == 0.01:\n",
    "        lr_dir = 'LR0_01'\n",
    "    elif lr == 0.001:\n",
    "        lr_dir = 'LR0_001'\n",
    "    elif lr == 0.1:\n",
    "        lr_dir = 'LR0_1'\n",
    "    else:\n",
    "        raise Exception('{lr} is not a correct learing rate')\n",
    "\n",
    "    Y = model.use(X)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    plt.suptitle(f'{arch}', fontsize=16)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(model.error_trace, color=color, label=method)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.ylim((0.0, 0.3))\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    plt.plot(Y, '-s', color=color, label=method)\n",
    "    plt.plot(T, '-o', color='green', label='Target')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Target or Predicted')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(f'Graphs/ResidualConnections/{train_style}/{lr_dir}/{method}_depth_{depth}_it{iteration + 1}_{conv_or_no_conv}.jpeg',  bbox_inches = 'tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689823c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T01:21:45.629794Z",
     "start_time": "2021-11-02T01:21:45.629786Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(X, T, n_hiddens, lr, method, train_style, verbose=False):\n",
    "    \n",
    "    epochs = 3000\n",
    "    convergence_threshold = 0.07\n",
    "\n",
    "    if verbose:\n",
    "        print('--------> {method} <--------')\n",
    "    model = NNet(1, n_hiddens, 1, method=method, verbose=verbose) \n",
    "    start = time.time()\n",
    "    model.train(X, T, epochs, lr, train_style=train_style,verbose=verbose)\n",
    "    end = time.time()\n",
    "    total_time = end - start\n",
    "    Y = model.use(X)\n",
    "    final_rmse = rmse(Y, T)\n",
    "    if verbose:\n",
    "        print(f'Total Time to Train {(total_time):.3f} seconds')\n",
    "        print(f'RMSE {final_rmse:.3f}\\n')\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'{method} Dead Neurons:')\n",
    "\n",
    "    dead_neurons, dead_layers = model.dead_neurons(verbose=False)\n",
    "\n",
    "    return (final_rmse <= convergence_threshold, [dead_neurons, dead_layers, total_time], model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36506a60",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d82be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_excel_results(specific_lr, pattern, connection, method, num_conv_or_no_conv, dead_neurons, dead_layers, time, did_converge=False):\n",
    "\n",
    "    def get_row_start_end(connection, did_converge, method):\n",
    "        if connection == 'non_residual' and did_converge:\n",
    "            if method == 'adam':\n",
    "                row_start = 2\n",
    "                row_end = 15\n",
    "            else:\n",
    "                row_start = 18\n",
    "                row_end = 31\n",
    "        \n",
    "        elif connection == 'residual' and did_converge:\n",
    "            if method == 'adam':\n",
    "                row_start = 3\n",
    "                row_end = 16\n",
    "            else:\n",
    "                row_start = 19\n",
    "                row_end = 32\n",
    "        \n",
    "        \n",
    "        elif connection == 'non_residual' and not did_converge:\n",
    "            if method == 'adam':\n",
    "                row_start = 34\n",
    "                row_end = 47\n",
    "            else:\n",
    "                row_start = 50\n",
    "                row_end = 63\n",
    "        \n",
    "        elif connection == 'residual' and not did_converge:\n",
    "            if method == 'adam':\n",
    "                row_start = 35\n",
    "                row_end = 48\n",
    "            else:\n",
    "                row_start = 51\n",
    "                row_end = 65\n",
    "        else: \n",
    "\n",
    "            raise Exception(f'connection must be \\'non_residual\\' or \\'residual\\'. Got {connection}')\n",
    "\n",
    "        return row_start, row_end\n",
    "                \n",
    "    df = pd.read_excel('WiderNetwork.xlsx', header=None)\n",
    "    \n",
    "    row_start, row_end = get_row_start_end(connection, did_converge, method)\n",
    "\n",
    "    if pattern == 'iterative':\n",
    "        total_c_or_nc_column = specific_lr['IT_TOTALCNC']\n",
    "        dead_neuron_column = specific_lr['IT_DEAD']\n",
    "        dead_layer_column = specific_lr['IT_DEAD_LAYERS']\n",
    "        training_time_column = specific_lr['IT_TIME']\n",
    "        \n",
    "        \n",
    "    elif pattern == 'batch':\n",
    "        total_c_or_nc_column = specific_lr['BATCH_TOTALCNC']\n",
    "        dead_neuron_column = specific_lr['BATCH_DEAD']\n",
    "        dead_layer_column = specific_lr['BATCH_DEAD_LAYERS']\n",
    "        training_time_column = specific_lr['BATCH_TIME']\n",
    "        \n",
    "        \n",
    "    else: \n",
    "        raise Exception(f'pattern must be \\'iterative\\' or \\'batch\\'. Got {pattern}')\n",
    "\n",
    "\n",
    "    for row, c_or_no_c, dead_n, dead_l, avg_time in zip(range(row_start, row_end, 2), num_conv_or_no_conv, dead_neurons, dead_layers, time):\n",
    "        # How many convergence or no convergence\n",
    "        df.iat[row, total_c_or_nc_column] = c_or_no_c\n",
    "\n",
    "        # Dead Neurons\n",
    "        df.iat[row, dead_neuron_column] = round(dead_n, 2)\n",
    "\n",
    "        # Dead Layers\n",
    "        df.iat[row, dead_layer_column] = round(dead_l, 2)\n",
    "\n",
    "        # Training Time\n",
    "        df.iat[row, training_time_column] = round(avg_time, 3)\n",
    "\n",
    "\n",
    "    df.to_excel('WiderNetwork.xlsx', sheet_name='Sheet1', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acc007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def archs_avg(lr, n_hiddens, adam_dead, adam_layers, adam_time, sgd_dead, sgd_layers, sgd_time, did_converge=False):\n",
    "\n",
    "    conv = 'CONVERGENCE' if did_converge else 'NO CONVERGENCE'\n",
    "    adam_avg_dead = np.average(adam_dead)\n",
    "    adam_avg_time = np.average(adam_time)\n",
    "    adam_avg_layers = np.average(adam_layers)\n",
    "\n",
    "    sgd_avg_dead = np.average(sgd_dead)\n",
    "    sgd_avg_time = np.average(sgd_time)\n",
    "    sgd_avg_layers = np.average(sgd_layers)\n",
    "\n",
    "\n",
    "    pretty_result = \"============================= COMPLETE =============================\\n\"\n",
    "    pretty_result += f'------ ARCH: [4 for _ in range({len(n_hiddens)})] LR: {lr} {conv}------\\n'\n",
    "    pretty_result += '****** Adam ******\\n'\n",
    "    pretty_result += f'Dead Neurons: {adam_avg_dead:.2f}\\tDead Layers: {adam_avg_layers:.3f}\\tTraining Time: {adam_avg_time:.3f}\\n\\n\\n'\n",
    "    pretty_result += '****** SGD ******\\n'\n",
    "    pretty_result += f'Dead Neurons: {sgd_avg_dead:.2f}\\tDead Layers: {sgd_avg_layers:.3f}\\tTraining Time: {sgd_avg_time:.3f}\\n\\n\\n'\n",
    "    pretty_result += \"============================= COMPLETE =============================\\n\\n\\n\\n\"\n",
    "    \n",
    "    print(pretty_result)\n",
    "\n",
    "    return adam_avg_dead, adam_avg_layers, adam_avg_time, sgd_avg_dead, sgd_avg_layers, sgd_avg_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59286cb9",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d667f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_lr(lr):\n",
    "    specific_lr = None\n",
    "    if lr == 0.01:\n",
    "        specific_lr = {'IT_TOTALCNC': 1, 'IT_DEAD': 2, 'IT_DEAD_LAYERS': 3, 'IT_TIME': 4, 'BATCH_TOTALCNC': 5, 'BATCH_DEAD': 6, 'BATCH_DEAD_LAYERS': 7,'BATCH_TIME': 8}\n",
    "    elif lr == 0.001:\n",
    "        specific_lr = {'IT_TOTALCNC': 11, 'IT_DEAD': 12, 'IT_DEAD_LAYERS': 13, 'IT_TIME': 14, 'BATCH_TOTALCNC': 15, 'BATCH_DEAD': 16, 'BATCH_DEAD_LAYERS': 17,'BATCH_TIME': 18}\n",
    "    elif lr == 0.1:\n",
    "        specific_lr = {'IT_TOTALCNC': 21, 'IT_DEAD': 22, 'IT_DEAD_LAYERS': 23, 'IT_TIME': 24, 'BATCH_TOTALCNC': 25, 'BATCH_DEAD': 26, 'BATCH_DEAD_LAYERS': 27,'BATCH_TIME': 28}\n",
    "    else:\n",
    "        raise Exception(f'{lr} is not a used learning rate.') \n",
    "    return specific_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f33a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(lr, train_style):\n",
    "    n_hiddens = []\n",
    "    width = 10\n",
    "    network_architectures = [(width, 2), (width, 5), (width, 10), (width, 15), (width, 20), (width, 25), (width, 30)]\n",
    "    for width, depth in network_architectures:\n",
    "        n_hiddens.append([width for _ in range(depth)])\n",
    "\n",
    "    specific_lr = get_specific_lr(lr)\n",
    "\n",
    "    adam_conv_all_dead = []\n",
    "    adam_conv_all_layers = []\n",
    "    adam_conv_all_time = []\n",
    "    adam_total_num_conv = []\n",
    "\n",
    "\n",
    "    adam_no_conv_all_dead = []\n",
    "    adam_no_conv_all_layers = []\n",
    "    adam_no_conv_all_time = []\n",
    "    adam_total_num_no_conv = []\n",
    " \n",
    "    \n",
    "\n",
    "    sgd_conv_all_dead = []\n",
    "    sgd_conv_all_layers = []\n",
    "    sgd_conv_all_time = []\n",
    "    sgd_total_num_conv = []\n",
    "\n",
    "    \n",
    "\n",
    "    sgd_no_conv_all_dead = []\n",
    "    sgd_no_conv_all_layers = []\n",
    "    sgd_no_conv_all_time = []\n",
    "    sgd_total_num_no_conv = []\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    print(colored('==================STARTING EXPERIMENT==================', 'yellow', attrs=['blink']))\n",
    "\n",
    "\n",
    "    for arch in n_hiddens:\n",
    "        adam_num_conv = 0\n",
    "        adam_conv_dead = []\n",
    "        adam_conv_layers = []\n",
    "        adam_conv_time = []\n",
    "        \n",
    "        adam_num_no_conv = 0\n",
    "        adam_no_conv_dead = []\n",
    "        adam_no_conv_layers = []\n",
    "        adam_no_conv_time = []\n",
    "        \n",
    "        sgd_num_conv = 0\n",
    "        sgd_conv_dead = []\n",
    "        sgd_conv_layers = []\n",
    "        sgd_conv_time = []\n",
    "        \n",
    "        sgd_num_no_conv = 0\n",
    "        sgd_no_conv_dead = []\n",
    "        sgd_no_conv_layers = []\n",
    "        sgd_no_conv_time = []\n",
    "        \n",
    "        NEURONS = 0\n",
    "        LAYERS = 1\n",
    "        TIME = 2\n",
    "\n",
    "        print(colored(f\"################# TRAINING #################\", 'magenta', attrs =['blink']))\n",
    "        print(colored(f'\\tARCH: [4 for _ in range({len(arch)})] LR: {lr}', 'magenta', attrs=['blink']))\n",
    "        print(colored(f\"############################################\\n\", 'magenta', attrs=['blink']))\n",
    "\n",
    "        for iteration in tqdm(range(10)):\n",
    "            \n",
    "            for method in ['adam', 'sgd']:\n",
    "                did_converge, results, model = run_experiment(X, T, arch, lr, method, train_style=train_style, verbose=False)\n",
    "                \n",
    "                if did_converge and method == 'adam':\n",
    "                    adam_conv_dead.append(results[NEURONS])\n",
    "                    adam_conv_layers.append(results[LAYERS])\n",
    "                    adam_conv_time.append(results[TIME])\n",
    "                    adam_num_conv += 1\n",
    "                    \n",
    "                elif did_converge and method == 'sgd':\n",
    "                    sgd_conv_dead.append(results[NEURONS])\n",
    "                    sgd_conv_layers.append(results[LAYERS])\n",
    "                    sgd_conv_time.append(results[TIME])\n",
    "                    sgd_num_conv += 1\n",
    "\n",
    "                elif not did_converge and method =='adam':\n",
    "                    adam_no_conv_dead.append(results[NEURONS])\n",
    "                    adam_no_conv_layers.append(results[LAYERS])\n",
    "                    adam_no_conv_time.append(results[TIME])\n",
    "                    adam_num_no_conv += 1\n",
    "\n",
    "                elif not did_converge and method == 'sgd':\n",
    "                    sgd_no_conv_dead.append(results[NEURONS])\n",
    "                    sgd_no_conv_layers.append(results[LAYERS])\n",
    "                    sgd_no_conv_time.append(results[TIME])\n",
    "                    sgd_num_no_conv += 1\n",
    "                    \n",
    "                else:\n",
    "                    raise Exception(f'Either method {method} or did_converge {did_converge} is wrong.')\n",
    "\n",
    "#                 display_graph(X, model, lr, arch, method, iteration, train_style, did_converge)\n",
    "\n",
    "        adam_total_num_conv.append(adam_num_conv)\n",
    "        adam_total_num_no_conv.append(adam_num_no_conv)\n",
    "\n",
    "        sgd_total_num_conv.append(sgd_num_conv)\n",
    "        sgd_total_num_no_conv.append(sgd_num_no_conv)\n",
    "\n",
    "        # Convergence\n",
    "        adam_conv_dead_avg, adam_conv_layer_avg, adam_conv_time_avg, sgd_conv_dead_avg, sgd_conv_layer_avg, sgd_conv_time_avg = \\\n",
    "                archs_avg(lr, arch, adam_conv_dead, adam_conv_layers, adam_conv_time, sgd_conv_dead, sgd_conv_layers, sgd_conv_time, did_converge=True)\n",
    "\n",
    "\n",
    "        adam_conv_all_dead.append(adam_conv_dead_avg)\n",
    "        adam_conv_all_layers.append(adam_conv_layer_avg)\n",
    "        adam_conv_all_time.append(adam_conv_time_avg)\n",
    "\n",
    "\n",
    "        sgd_conv_all_dead.append(sgd_conv_dead_avg)\n",
    "        sgd_conv_all_layers.append(sgd_conv_layer_avg)\n",
    "        sgd_conv_all_time.append(sgd_conv_time_avg)\n",
    "  \n",
    "\n",
    "\n",
    "        # No Convergence\n",
    "        adam_no_conv_dead_avg, adam_no_conv_layer_avg, adam_no_conv_time_avg, sgd_no_conv_dead_avg, sgd_no_conv_layer_avg, sgd_no_conv_time_avg = \\\n",
    "                archs_avg(lr, arch, adam_no_conv_dead, adam_no_conv_layers, adam_no_conv_time, sgd_no_conv_dead, sgd_no_conv_layers, sgd_no_conv_time)\n",
    "\n",
    "\n",
    "        adam_no_conv_all_dead.append(adam_no_conv_dead_avg)\n",
    "        adam_no_conv_all_layers.append(adam_no_conv_layer_avg)\n",
    "        adam_no_conv_all_time.append(adam_no_conv_time_avg)\n",
    "\n",
    "\n",
    "        sgd_no_conv_all_dead.append(sgd_no_conv_dead_avg)\n",
    "        sgd_no_conv_all_layers.append(sgd_no_conv_layer_avg)\n",
    "        sgd_no_conv_all_time.append(sgd_no_conv_time_avg)\n",
    "\n",
    "\n",
    "    update_excel_results(specific_lr, train_style, 'residual', 'adam', adam_total_num_conv, adam_conv_all_dead, adam_conv_all_layers, adam_conv_all_time, did_converge=True)\n",
    "    update_excel_results(specific_lr, train_style, 'residual', 'adam', adam_total_num_no_conv, adam_no_conv_all_dead, adam_no_conv_all_layers, adam_no_conv_all_time)\n",
    "\n",
    "    update_excel_results(specific_lr, train_style, 'residual', 'sgd', sgd_total_num_conv, sgd_conv_all_dead, sgd_conv_all_layers, sgd_conv_all_time, did_converge=True)\n",
    "    update_excel_results(specific_lr, train_style, 'residual', 'sgd', sgd_total_num_no_conv, sgd_no_conv_all_dead, sgd_no_conv_all_layers, sgd_no_conv_all_time)\n",
    "\n",
    "\n",
    "    print(colored('==================EXPERIMENT COMPLETE ==================', 'yellow', attrs=['blink']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all():\n",
    "    main(lr=0.01, train_style='iterative')\n",
    "    main(lr=0.001, train_style='iterative')\n",
    "    main(lr=0.1, train_style='iterative')\n",
    "\n",
    "    main(lr=0.01, train_style='batch')\n",
    "    main(lr=0.001, train_style='batch')\n",
    "    main(lr=0.1, train_style='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe2bcce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca12067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d8aeb55645092b5ba1a1f1c70dced96779d3214ac1f3d068b8004066b2b1643"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
